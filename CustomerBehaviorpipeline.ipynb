{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VY_lBjJjWyH",
        "outputId": "7a6d94dc-4be1-498c-903f-e0eaa247c39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56-lh5eoY19C"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import re\n",
        "import time\n",
        "from typing import List, Optional, Union, Dict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        " \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer,AddMissingIndicator,CategoricalImputer\n",
        "from feature_engine.transformation import LogTransformer\n",
        "from feature_engine.encoding import OrdinalEncoder,OneHotEncoder\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# to build the models\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Vp-ef-Y8fM",
        "outputId": "7a5bc207-f239-46b2-b90d-2d0a498ec7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class handleMixLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "    self.variables = variables\n",
        "    self.keys:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.tol = tol\n",
        "    self.target = target\n",
        "    self.all_unique_feature_type:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.top_unique_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.unique_rare_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "\n",
        "\n",
        "\n",
        "  # we check the top 10 cardinal value which have monotonic relation with target column store that in keys\n",
        "  # go through the column if it have mixed or comma seperated values the carefully store all unique cardinal values store in all_unique_feature_type\n",
        "  # based on tolerance it take top cardinal values default value is 10 and store those top values in top_unique_feature_type_\n",
        "  def fit(self, X: pd.DataFrame,y:pd.Series):\n",
        "        X = X.dropna().copy()\n",
        "        X[self.target] = y\n",
        "        X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "        if X[self.target].dtypes != float:\n",
        "          X[self.target] = X[self.target].str.replace(',','').astype(float)\n",
        "\n",
        "        if isinstance(self.variables,list):\n",
        "          self.keys = list()\n",
        "          variable_keys = list()\n",
        "          self.all_unique_feature_type = list()\n",
        "          self.top_unique_feature_type_ = list()\n",
        "          self.unique_rare_feature_type_ = list()\n",
        "\n",
        "          for index in range(0,len(self.variables)):\n",
        "\n",
        "            # fetch all top categories of variable related to target variables in descending order \n",
        "            for key in X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False).keys():\n",
        "                    variable_keys.append(key)\n",
        "            self.keys.append({self.variables[index]:variable_keys})\n",
        "            variable_keys = list()\n",
        "\n",
        "            # remove duplicated categories as they are all mixed up\n",
        "            self.all_unique_feature_type.append({self.variables[index]:list()})\n",
        "           \n",
        "            # collect all unique categories from variables   \n",
        "            for value in X[self.variables[index]]:\n",
        "              if ',' in value:\n",
        "                for item in value.split(','):\n",
        "                  if item.strip() not in self.all_unique_feature_type[index][self.variables[index]]:\n",
        "                    self.all_unique_feature_type[index][self.variables[index]].append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.all_unique_feature_type[index][self.variables[index]]:\n",
        "                  self.all_unique_feature_type[index][self.variables[index]].append(value.strip())  \n",
        "            \n",
        "            self.top_unique_feature_type_.append({self.variables[index]:list()})\n",
        "\n",
        "            # Seperate less related unique categories from top categorials for rare labeling\n",
        "            for value in self.keys[index][self.variables[index]][:self.tol[index]]:\n",
        "              if isinstance(value,tuple):\n",
        "                for item in value:\n",
        "                  if item.strip() not in self.top_unique_feature_type_[index][self.variables[index]]:\n",
        "                      self.top_unique_feature_type_[index][self.variables[index]].append(item.strip())\n",
        "              elif ',' in value:\n",
        "                  for item in value.split(','):\n",
        "                    if item.strip() not in self.top_unique_feature_type_[index][self.variables[index]]:\n",
        "                      self.top_unique_feature_type_[index][self.variables[index]].append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.top_unique_feature_type_[index][self.variables[index]]:\n",
        "                  self.top_unique_feature_type_[index][self.variables[index]].append(value.strip())\n",
        "\n",
        "            self.top_unique_feature_type_[index][self.variables[index]] = self.top_unique_feature_type_[index][self.variables[index]] + ['Rare']\n",
        "            \n",
        "            self.unique_rare_feature_type_.append({self.variables[index]:list()})\n",
        "            self.unique_rare_feature_type_[index][self.variables[index]] = [value for value in self.all_unique_feature_type[index][self.variables[index]] if value not in self.top_unique_feature_type_[index][self.variables[index]]]\n",
        "\n",
        "            \n",
        "        if isinstance(self.variables,str):\n",
        "          self.keys = list()\n",
        "          self.all_unique_feature_type = list()\n",
        "          self.top_unique_feature_type_ = list()\n",
        "          self.unique_rare_feature_type_ = list()  \n",
        "\n",
        "          # fetch all top categories of variable related to target variables in descending order \n",
        "          for key in X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).keys():\n",
        "                    self.keys.append(key)\n",
        "           \n",
        "          # collect all unique categories from variables   \n",
        "          for value in X[self.variables]:\n",
        "              if ',' in value:\n",
        "                for item in value.split(','):\n",
        "                  if item.strip() not in self.all_unique_feature_type:\n",
        "                    self.all_unique_feature_type.append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.all_unique_feature_type:\n",
        "                  self.all_unique_feature_type.append(value.strip())  \n",
        "            \n",
        "\n",
        "          # Seperate less related unique categories from top categorials for rare labeling\n",
        "          for value in self.keys[:self.tol]:\n",
        "              if isinstance(value,tuple):\n",
        "                for item in value:\n",
        "                  if item.strip() not in self.top_unique_feature_type_:\n",
        "                      self.top_unique_feature_type_.append(item.strip())\n",
        "              elif ',' in value:\n",
        "                  for item in value.split(','):\n",
        "                    if item.strip() not in self.top_unique_feature_type_:\n",
        "                      self.top_unique_feature_type_.append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.top_unique_feature_type_:\n",
        "                  self.top_unique_feature_type_.append(value.strip())\n",
        "\n",
        "          self.top_unique_feature_type_ = self.top_unique_feature_type_ + ['Rare']  \n",
        "          self.unique_rare_feature_type_ = [value for value in self.all_unique_feature_type if value not in self.top_unique_feature_type_]\n",
        "\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "\n",
        "  def transform(self, X: pd.DataFrame):\n",
        "        X = X.copy()\n",
        "        \n",
        "        if isinstance(self.variables,list):\n",
        "          for index in range(0,len(self.variables)):\n",
        "            # adding new columns of unique labels in datasets\n",
        "            for value in self.top_unique_feature_type_[index][self.variables[index]]:\n",
        "              X[f'{self.variables[index]}_{value}'] = np.zeros(X.shape[0])\n",
        "\n",
        "            # Adding 1 and 0's to those newly added columns\n",
        "            for value in self.top_unique_feature_type_[index][self.variables[index]]:\n",
        "              for indx in range(0,X.shape[0]):\n",
        "                if  ',' in  X[self.variables[index]][indx]:\n",
        "                  for item in X[self.variables[index]][indx].split(','):\n",
        "                    if item.strip() not in self.unique_rare_feature_type_[index][self.variables[index]]:\n",
        "                        X[f'{self.variables[index]}_{value}'][indx] = 1\n",
        "                    if item.strip() in self.unique_rare_feature_type_[index][self.variables[index]]:\n",
        "                      X[f'{self.variables[index]}_Rare'][indx] = 1\n",
        "                else:\n",
        "                  if value.strip() == X[self.variables[index]][indx].strip():\n",
        "                        X[f'{self.variables[index]}_{value}'][indx] = 1\n",
        "                  if X[self.variables[index]][indx].strip() in self.unique_rare_feature_type_[index][self.variables[index]]:\n",
        "                      X[f'{self.variables[index]}_Rare'][indx] = 1\n",
        "\n",
        "        if isinstance(self.variables,str):  \n",
        "        # adding new columns of unique labels in datasets\n",
        "            for value in self.top_unique_feature_type_:\n",
        "              X[f'{self.variables}_{value}'] = np.zeros(X.shape[0])\n",
        "\n",
        "            # Adding 1 and 0's to those newly added columns\n",
        "            for value in self.top_unique_feature_type_:\n",
        "              for indx in range(0,X.shape[0]):\n",
        "                if  ',' in  X[self.variables][indx]:\n",
        "                  for item in X[self.variables][indx].split(','):\n",
        "                    if item.strip() not in self.unique_rare_feature_type_:\n",
        "                        X[f'{self.variables}_{value}'][indx] = 1\n",
        "                    if item.strip() in self.unique_rare_feature_type_:\n",
        "                      X[f'{self.variables}_Rare'][indx] = 1\n",
        "                else:\n",
        "                  if value.strip() == X[self.variables][indx].strip():\n",
        "                        X[f'{self.variables}_{value}'][indx] = 1\n",
        "                  if X[self.variables][indx].strip() in self.unique_rare_feature_type_:\n",
        "                      X[f'{self.variables}_Rare'][indx] = 1\n",
        "       \n",
        "        X = X.drop(self.variables,axis=1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "IwIE9MNidizS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class handleRankingLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "        self.variables = variables\n",
        "        self.listed_in_ranks:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "        self.tol = tol\n",
        "        self.target = target\n",
        "        self.listed_in_dict:Union[None,Dict,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "\n",
        "        if (isinstance(self.variables,list) and isinstance(self.tol,list)) and (len(self.variables) != len(self.tol)):\n",
        "          raise Exception(\"Number of variable and number of tolerance should be equal in length, check the varables and tol!!\")\n",
        "\n",
        "  \n",
        "  # This method checks relation with target columns based on that montonic relation assign ordinal values to top 10 features and map those feature on train and test datasets \n",
        "  def fit(self,X:pd.DataFrame,y:pd.Series = None):\n",
        "    X[self.target] = y\n",
        "    X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "    if X[self.target].dtypes != float:\n",
        "      X[self.target] = X[self.target].str.replace(',','').astype(float) \n",
        "\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_ranks = list()\n",
        "      for index in range(0,len(self.variables)):\n",
        "        if len(df[self.variables[index]].unique()) > 10:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks.append({f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False)[:self.tol[index]].to_dict().keys())})\n",
        "        else:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks.append({f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False).to_dict().keys())})\n",
        "    \n",
        "    if isinstance(self.variables,str):\n",
        "      self.listed_in_ranks = list()\n",
        "      if len(df[self.variables].unique()) > 10:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False)[:self.tol].to_dict().keys())\n",
        "      else:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).to_dict().keys())   \n",
        "\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_dict = list()\n",
        "      list_in_dict = dict()\n",
        "      for index in range(0,len(self.variables)):\n",
        "        # replacing non top categories  \n",
        "        X[self.variables[index]] = X[self.variables[index]].apply(lambda value:value if value in self.listed_in_ranks[index][self.variables[index]] else 'Rare')   \n",
        "              \n",
        "        self.listed_in_ranks[index][self.variables[index]] = self.listed_in_ranks[index][self.variables[index]]+ ['Rare']\n",
        "        # # Creating dictionary for mapping categories \n",
        "        for indx in range(0,len(self.listed_in_ranks[index][self.variables[index]])):\n",
        "           list_in_dict[self.listed_in_ranks[index][self.variables[index]][indx]] = indx\n",
        "        self.listed_in_dict.append({self.variables[index]:list_in_dict})\n",
        "\n",
        "        list_in_dict = dict()\n",
        "        # # replacing categories\n",
        "        X[self.variables[index]] = X[self.variables[index]].map(self.listed_in_dict[index][self.variables[index]]) \n",
        "    \n",
        "    if isinstance(self.variables,str):\n",
        "      self.listed_in_dict = dict()\n",
        "      # replacing non top categories  \n",
        "      X[self.variables] = X[self.variables].apply(lambda value:value if value in self.listed_in_ranks else 'Rare')   \n",
        "            \n",
        "      self.listed_in_ranks = self.listed_in_ranks + ['Rare']\n",
        "      # # Creating dictionary for mapping categories \n",
        "      for index in range(0,len(self.listed_in_ranks)):\n",
        "        self.listed_in_dict[self.listed_in_ranks[index]] = index\n",
        "\n",
        "      # # replacing categories\n",
        "      X[self.variables] = X[self.variables].map(self.listed_in_dict) \n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "xFWdtwFKJ7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class featureSelection(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,alpha,random_state):\n",
        "    self.selected_feats = None\n",
        "    self.__alpha = alpha\n",
        "    self.__random_state = random_state \n",
        "    self.sel_ = None\n",
        "\n",
        "  def fit(self,X,y):\n",
        "   self.sel_ = SelectFromModel(Lasso(alpha=self.__alpha, random_state=self.__random_state))\n",
        "   self.sel_.fit(X, y)  \n",
        "   return self\n",
        "\n",
        "  def transform(self,X): \n",
        "   self.selected_feats = X.columns[(self.sel_.get_support())]\n",
        "   return X[self.selected_feats]"
      ],
      "metadata": {
        "id": "ohBNq1znssgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZomatoModelTrain(handleMixLabels,handleRankingLabels,featureSelection):\n",
        "\n",
        "  def __init__(self,df):\n",
        "    self.__df = df\n",
        "    self.__target = 'approx_cost(for two people)'\n",
        "    self.__df[self.__target] = self.__df[self.__target].str.replace(',','').astype(float)\n",
        "    self.__random_state = 100\n",
        "    self.__alpha = 0.001\n",
        "    self.__test_size = 0.33\n",
        "    self.__handleRankingLabels = handleRankingLabels\n",
        "    self.__handleMixLabels = handleMixLabels\n",
        "    self.__featureSelection = featureSelection\n",
        "    self.__variable_to_drop = ['url','address','phone','reviews_list','name','dish_liked','menu_item'] + [self.__target]\n",
        "    self.__AddMissingIndicatorVariables = ['votes','rate']\n",
        "    self.__MeanMedianImputerVarables = ['votes']\n",
        "    self.__CategoricalImputerModeVarables = ['rate','cuisines','rest_type']\n",
        "    self.__LogTransformerVarables = ['votes']\n",
        "    self.__OrdinalEncoderVariables = ['rate']\n",
        "    self.__OneHotEncoderVariables = ['online_order','book_table']\n",
        "    self.__handleRankingLabels_var = {'variables':['listed_in(type)','listed_in(city)','location'],'tolerance':[10,15,15]}\n",
        "    self.__handleMixLabels_var ={'variables':['rest_type','cuisines'],'tolerance':[10,15]}\n",
        "\n",
        "\n",
        "  def applyModelTrain(self):\n",
        "    X_train,X_test,y_train,y_test = self.__dataSpliter()\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)  \n",
        "    return X_train,X_test,y_train.fillna(y_train.median()),y_test.fillna(y_test.median())\n",
        "\n",
        "  # Splits the data into train and test set\n",
        "  def __dataSpliter(self):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df.drop(self.__variable_to_drop,axis=1), df[self.__target], test_size=self.__test_size, random_state=42)\n",
        "    X_train,X_test,y_train,y_test = X_train.reset_index().drop('index',axis=1),X_test.reset_index().drop('index',axis=1),y_train.reset_index().drop('index',axis=1),y_test.reset_index().drop('index',axis=1)\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  # This method andle noisy data from rate and votes columns\n",
        "  def __dataCleanar(self,X_train,X_test):\n",
        "    # replacing '-' with nan in rate variable\n",
        "    X_train['rate'] = X_train['rate'].replace('-',np.nan)  \n",
        "    X_test['rate'] = X_test['rate'].replace('-',np.nan)\n",
        "\n",
        "    # replacing '0' with nan in votes variable\n",
        "    X_train['votes'] = X_train['votes'].replace(0,np.nan)\n",
        "    X_test['votes'] = X_test['votes'].replace(0,np.nan)\n",
        "    \n",
        "    # replacing '/5' with ' in rates variable\n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    \n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "\n",
        "    return X_train,X_test\n",
        "\n",
        "  # This method is for rate column where based on certain ranges we made this column to categorical oridinal variable\n",
        "  def handleRating(self,X_train,X_test,feature):\n",
        "    return np.where(X_train[feature]==np.nan,np.nan,np.where(X_train[feature]==0,'New',np.where(X_train[feature]<2.5,'Poor',np.where((X_train[feature]>2.5) | (X_train[feature]<3.5),'Average','Good')))),np.where(X_test[feature]==np.nan,np.nan,np.where(X_test[feature]==0,'New',np.where(X_test[feature]<2.5,'Poor',np.where((X_test[feature]>2.5) | (X_test[feature]<3.5),'Average','Good')))) \n",
        "\n",
        "  def featurePipeline(self):\n",
        "    pipe = Pipeline([\n",
        "      #  Missing indicator\n",
        "      ('Add missing indicator',AddMissingIndicator(\n",
        "          variables=self.__AddMissingIndicatorVariables)),\n",
        "    \n",
        "      #   Median Missing Imputation\n",
        "      ('Median Missing Imputation',MeanMedianImputer(\n",
        "          imputation_method='median', variables=self.__MeanMedianImputerVarables)),\n",
        "\n",
        "      #   Mode Missing Imputation\n",
        "      ('Mode Missing Imputation',CategoricalImputer(\n",
        "          imputation_method='frequent', variables=self.__CategoricalImputerModeVarables)),        \n",
        "\n",
        "      # Feature Transformation\n",
        "      ('LogTransformer',LogTransformer(\n",
        "          variables=self.__LogTransformerVarables)),\n",
        "\n",
        "      #  Ordinal Encoder\n",
        "      ('OrdinalEncoder',OrdinalEncoder(\n",
        "          encoding_method='ordered',variables=self.__OrdinalEncoderVariables)),\n",
        "\n",
        "      #  OneHotEncoder\n",
        "      ('OneHotEncoder',OneHotEncoder(\n",
        "          drop_last=True,variables=self.__OneHotEncoderVariables)),\n",
        "\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels listed_in(type)',self.__handleRankingLabels(\n",
        "          variables=self.__handleRankingLabels_var['variables'],tol=self.__handleRankingLabels_var['tolerance'],target=self.__target)),        \n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation cuisines', self.__handleMixLabels(\n",
        "          variables=self.__handleMixLabels_var['variables'],tol=self.__handleMixLabels_var['tolerance'],target=self.__target)), \n",
        "\n",
        "      # #  feature selection\n",
        "      # ('feature selection',featureSelection(alpha=self.__alpha, random_state=self.__random_state)),\n",
        "\n",
        "      # Model\n",
        "      # ('Random Forest Model',RandomForestRegressor(bootstrap= True,max_depth= 10,min_samples_leaf= 2,min_samples_split= 2,n_estimators= 100,oob_score= True))\n",
        "    ])\n",
        "\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "PFjsyhbgZaCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/zomato.csv')"
      ],
      "metadata": {
        "id": "FgC9AoxBNIQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zmt = ZomatoModelTrain(df)"
      ],
      "metadata": {
        "id": "1FNr6WINyFua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = zmt.applyModelTrain()"
      ],
      "metadata": {
        "id": "8H7utpO1ysl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xVu433aTFa5",
        "outputId": "57e46ed4-4569-4933-d925-8cd695312e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34650 entries, 0 to 34649\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   online_order     34650 non-null  object \n",
            " 1   book_table       34650 non-null  object \n",
            " 2   rate             29422 non-null  float64\n",
            " 3   votes            27944 non-null  float64\n",
            " 4   location         34638 non-null  object \n",
            " 5   rest_type        34514 non-null  object \n",
            " 6   cuisines         34621 non-null  object \n",
            " 7   listed_in(type)  34650 non-null  object \n",
            " 8   listed_in(city)  34650 non-null  object \n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'],X_test['rate'] = zmt.handleRating(X_train,X_test,'rate')"
      ],
      "metadata": {
        "id": "T2e-gEmgJ3Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'].unique(),X_test['rate'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEcfeX2pM0UX",
        "outputId": "887cf30d-fb1d-4f25-c93c-21b2be35cdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Good', 'Average', 'New', 'Poor'], dtype=object),\n",
              " array(['Average', 'New', 'Good', 'Poor'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = zmt.featurePipeline()"
      ],
      "metadata": {
        "id": "pJZMIasqRqct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "p8dMOIakFORx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "train = pipe.transform(X_train)\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        " \n",
        "# print the difference between start\n",
        "# and end time in milli. secs\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start) * 10**3, \"ms\")"
      ],
      "metadata": {
        "id": "05BaFOMOwz_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c144702-be88-435c-b6f9-51d5532f9d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time of execution of above program is : 700138.5018825531 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "NmRm0Q4JRfHC",
        "outputId": "a72e822b-6a00-4012-e5a8-b8961bfaa9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       rate     votes  location  listed_in(type)  listed_in(city)  votes_na  \\\n",
              "9725      2  5.762051        16                5               16         0   \n",
              "8411      2  5.056246        16                5               16         0   \n",
              "1228      0  4.290459        16                4               16         1   \n",
              "3669      2  3.218876        16                5               16         0   \n",
              "33185     1  4.290459         1                3                1         1   \n",
              "\n",
              "       online_order_No  book_table_No  rest_type_Fine Dining  rest_type_Bar  \\\n",
              "9725                 1              1                    0.0            1.0   \n",
              "8411                 0              1                    0.0            0.0   \n",
              "1228                 1              1                    0.0            0.0   \n",
              "3669                 0              1                    0.0            0.0   \n",
              "33185                1              1                    0.0            0.0   \n",
              "\n",
              "       rest_type_Microbrewery  rest_type_Lounge  rest_type_Club  \\\n",
              "9725                      0.0               0.0             0.0   \n",
              "8411                      0.0               0.0             0.0   \n",
              "1228                      0.0               0.0             0.0   \n",
              "3669                      0.0               0.0             0.0   \n",
              "33185                     0.0               0.0             0.0   \n",
              "\n",
              "       rest_type_Casual Dining  rest_type_Quick Bites  rest_type_Rare  \\\n",
              "9725                       0.0                    0.0             0.0   \n",
              "8411                       0.0                    0.0             1.0   \n",
              "1228                       0.0                    1.0             0.0   \n",
              "3669                       0.0                    0.0             1.0   \n",
              "33185                      0.0                    1.0             0.0   \n",
              "\n",
              "       cuisines_French  cuisines_Italian  cuisines_North Indian  \\\n",
              "9725               1.0               1.0                    1.0   \n",
              "8411               1.0               1.0                    1.0   \n",
              "1228               0.0               0.0                    0.0   \n",
              "3669               0.0               0.0                    0.0   \n",
              "33185              1.0               1.0                    1.0   \n",
              "\n",
              "       cuisines_Continental  cuisines_Japanese  cuisines_Chinese  \\\n",
              "9725                    1.0                1.0               1.0   \n",
              "8411                    1.0                1.0               1.0   \n",
              "1228                    0.0                0.0               0.0   \n",
              "3669                    0.0                0.0               0.0   \n",
              "33185                   1.0                1.0               1.0   \n",
              "\n",
              "       cuisines_South Indian  cuisines_Steak  cuisines_Mediterranean  \\\n",
              "9725                     1.0             1.0                     1.0   \n",
              "8411                     1.0             1.0                     1.0   \n",
              "1228                     0.0             0.0                     0.0   \n",
              "3669                     0.0             0.0                     0.0   \n",
              "33185                    1.0             1.0                     1.0   \n",
              "\n",
              "       cuisines_Grill  cuisines_Kashmiri  cuisines_Mughlai  cuisines_Asian  \\\n",
              "9725              1.0                1.0               1.0             1.0   \n",
              "8411              1.0                1.0               1.0             1.0   \n",
              "1228              0.0                0.0               0.0             0.0   \n",
              "3669              0.0                0.0               0.0             0.0   \n",
              "33185             1.0                1.0               1.0             1.0   \n",
              "\n",
              "       cuisines_Mangalorean  cuisines_Konkan  cuisines_Seafood  \\\n",
              "9725                    1.0              1.0               1.0   \n",
              "8411                    1.0              1.0               1.0   \n",
              "1228                    0.0              0.0               0.0   \n",
              "3669                    0.0              0.0               0.0   \n",
              "33185                   1.0              1.0               1.0   \n",
              "\n",
              "       cuisines_Kerala  cuisines_Thai  cuisines_European  cuisines_Salad  \\\n",
              "9725               1.0            1.0                1.0             1.0   \n",
              "8411               1.0            1.0                1.0             1.0   \n",
              "1228               0.0            0.0                0.0             0.0   \n",
              "3669               0.0            0.0                0.0             0.0   \n",
              "33185              1.0            1.0                1.0             1.0   \n",
              "\n",
              "       cuisines_American  cuisines_Tex-Mex  cuisines_Rare  \n",
              "9725                 1.0               1.0            1.0  \n",
              "8411                 1.0               1.0            1.0  \n",
              "1228                 0.0               0.0            1.0  \n",
              "3669                 0.0               0.0            1.0  \n",
              "33185                1.0               1.0            1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-868494b8-8c28-4f7f-a398-b3ade4a8d2f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>votes</th>\n",
              "      <th>location</th>\n",
              "      <th>listed_in(type)</th>\n",
              "      <th>listed_in(city)</th>\n",
              "      <th>votes_na</th>\n",
              "      <th>online_order_No</th>\n",
              "      <th>book_table_No</th>\n",
              "      <th>rest_type_Fine Dining</th>\n",
              "      <th>rest_type_Bar</th>\n",
              "      <th>rest_type_Microbrewery</th>\n",
              "      <th>rest_type_Lounge</th>\n",
              "      <th>rest_type_Club</th>\n",
              "      <th>rest_type_Casual Dining</th>\n",
              "      <th>rest_type_Quick Bites</th>\n",
              "      <th>rest_type_Rare</th>\n",
              "      <th>cuisines_French</th>\n",
              "      <th>cuisines_Italian</th>\n",
              "      <th>cuisines_North Indian</th>\n",
              "      <th>cuisines_Continental</th>\n",
              "      <th>cuisines_Japanese</th>\n",
              "      <th>cuisines_Chinese</th>\n",
              "      <th>cuisines_South Indian</th>\n",
              "      <th>cuisines_Steak</th>\n",
              "      <th>cuisines_Mediterranean</th>\n",
              "      <th>cuisines_Grill</th>\n",
              "      <th>cuisines_Kashmiri</th>\n",
              "      <th>cuisines_Mughlai</th>\n",
              "      <th>cuisines_Asian</th>\n",
              "      <th>cuisines_Mangalorean</th>\n",
              "      <th>cuisines_Konkan</th>\n",
              "      <th>cuisines_Seafood</th>\n",
              "      <th>cuisines_Kerala</th>\n",
              "      <th>cuisines_Thai</th>\n",
              "      <th>cuisines_European</th>\n",
              "      <th>cuisines_Salad</th>\n",
              "      <th>cuisines_American</th>\n",
              "      <th>cuisines_Tex-Mex</th>\n",
              "      <th>cuisines_Rare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9725</th>\n",
              "      <td>2</td>\n",
              "      <td>5.762051</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8411</th>\n",
              "      <td>2</td>\n",
              "      <td>5.056246</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228</th>\n",
              "      <td>0</td>\n",
              "      <td>4.290459</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3669</th>\n",
              "      <td>2</td>\n",
              "      <td>3.218876</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33185</th>\n",
              "      <td>1</td>\n",
              "      <td>4.290459</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-868494b8-8c28-4f7f-a398-b3ade4a8d2f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-868494b8-8c28-4f7f-a398-b3ade4a8d2f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-868494b8-8c28-4f7f-a398-b3ade4a8d2f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fs = featureSelection(alpha=0.01,random_state=100)"
      ],
      "metadata": {
        "id": "ViQYkPD4JUb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = fs.fit(train,y_train)"
      ],
      "metadata": {
        "id": "3N5qhInzLy8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = fs.transform(train)"
      ],
      "metadata": {
        "id": "8ZvcTi0AL4wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['rest_type_Rare'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MbVowhOiZqK",
        "outputId": "ef398d5a-5c29-4b17-9786-a0d9a67db812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    20893\n",
              "1.0    13757\n",
              "Name: rest_type_Rare, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['cuisines_Rare'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCK4mx2YjaBR",
        "outputId": "66253824-bcde-4e3a-e8fb-e70542c0f3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    30526\n",
              "0.0     4124\n",
              "Name: cuisines_Rare, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(bootstrap= True,max_depth= 10,min_samples_leaf= 2,min_samples_split= 2,n_estimators= 100,oob_score= True)"
      ],
      "metadata": {
        "id": "hyiqStZtMPBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = rf.fit(train,y_train)"
      ],
      "metadata": {
        "id": "FflmBg_mMURc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = rf.predict(train)"
      ],
      "metadata": {
        "id": "Ob7wafDrMXxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "bTcFgCxFeNTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOepxlvwefLd",
        "outputId": "72afb5eb-7fa7-4203-f240-8ae71e4727df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8498848452864205"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_train,pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbnOQdGkhDL-",
        "outputId": "40e79370-1ada-485e-fe36-37cf2eb0ecb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170.44688883044955"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_train,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbcENiDLhJNY",
        "outputId": "b593fdd4-86df-4bc3-ae44-6cab624ea4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121.36278450661764"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "residual_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "TXR38oIz8a5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# record start time\n",
        "start = time.time()\n",
        "\n",
        "test = pipe.transform(X_test)\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        " \n",
        "# print the difference between start\n",
        "# and end time in milli. secs\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start) * 10**3, \"ms\")"
      ],
      "metadata": {
        "id": "vIz_-NHRe64l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bde92f0-cafc-472b-e7ab-78050c554fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time of execution of above program is : 363524.0981578827 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = fs.transform(test)"
      ],
      "metadata": {
        "id": "dNofwaQ7fF00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = rf.predict(test)"
      ],
      "metadata": {
        "id": "d42TkJ2RfK8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_oxN-C0fUi9",
        "outputId": "3fe8286d-fdfb-4ed9-aef4-036e2b26ad96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8313167562011934"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_test,pred_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grkQP1yNg76w",
        "outputId": "c681d657-2422-4944-cc82-11da6aef6a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177.72311404664327"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test,pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GAimIQKhX03",
        "outputId": "29777d57-8d11-4451-9cfb-c1d799c08706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124.89226517167847"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}