{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmpj6yTKCCCM",
        "outputId": "a86c9c55-daab-44d1-c158-1d191b0757e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXOBmcQEq22m"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import re\n",
        "import time\n",
        "from typing import List, Optional, Union, Dict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        " \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer,AddMissingIndicator,CategoricalImputer\n",
        "from feature_engine.transformation import LogTransformer\n",
        "from feature_engine.encoding import OrdinalEncoder,OneHotEncoder\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# to build the models\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hvgoy6jBZ71",
        "outputId": "687f3956-1fbf-4b81-d6dd-ea827f67e657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class handleRankingLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "        self.variables = variables\n",
        "        self.listed_in_ranks:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "        self.tol = tol\n",
        "        self.target = target\n",
        "        self.listed_in_dict:Union[None,Dict,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "\n",
        "        if (isinstance(self.variables,list) and isinstance(self.tol,list)) and (len(self.variables) != len(self.tol)):\n",
        "          raise Exception(\"Number of variable and number of tolerance should be equal in length, check the varables and tol!!\")\n",
        "\n",
        "  \n",
        "  # This method checks relation with target columns based on that montonic relation assign ordinal values to top 10 features and map those feature on train and test datasets \n",
        "  def fit(self,X:pd.DataFrame,y:pd.Series = None):\n",
        "    X[self.target] = y\n",
        "    X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "    if X[self.target].dtypes != float:\n",
        "      X[self.target] = X[self.target].str.replace(',','').astype(float) \n",
        "\n",
        "    # If user provide multiple variable this will find the top monotonic cardinal values of that variable with target variable and stores those top values.\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_ranks = [{f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False)[:self.tol[index]].to_dict().keys())}\n",
        "                              if len(df[self.variables[index]].unique()) > 10 \n",
        "                              else {f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False).to_dict().keys())} \n",
        "                              for index in range(0,len(self.variables))]\n",
        "\n",
        "    # If user provide single variable this will find the top monotonic cardinal values of that variable with target variable and stores that top values.\n",
        "    if isinstance(self.variables,str):\n",
        "      self.listed_in_ranks = self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False)[:self.tol].to_dict().keys()) if len(df[self.variables].unique()) > 10 else list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).to_dict().keys())\n",
        "       \n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_dict = list()\n",
        "      list_in_dict = dict()\n",
        "      for index in range(0,len(self.variables)):\n",
        "        # replacing non top categories  \n",
        "        X[self.variables[index]] = X[self.variables[index]].apply(lambda value:value if value in self.listed_in_ranks[index][self.variables[index]] else 'Rare')   \n",
        "              \n",
        "        self.listed_in_ranks[index][self.variables[index]] = self.listed_in_ranks[index][self.variables[index]]+ ['Rare']\n",
        "        # # Creating dictionary for mapping categories \n",
        "        for indx in range(0,len(self.listed_in_ranks[index][self.variables[index]])):\n",
        "           list_in_dict[self.listed_in_ranks[index][self.variables[index]][indx]] = indx\n",
        "        self.listed_in_dict.append({self.variables[index]:list_in_dict})\n",
        "\n",
        "        list_in_dict = dict()\n",
        "        # # replacing categories\n",
        "        X[self.variables[index]] = X[self.variables[index]].map(self.listed_in_dict[index][self.variables[index]]) \n",
        "    \n",
        "    if isinstance(self.variables,str):\n",
        "      self.listed_in_dict = dict()\n",
        "      # replacing non top categories  \n",
        "      X[self.variables] = X[self.variables].apply(lambda value:value if value in self.listed_in_ranks else 'Rare')   \n",
        "            \n",
        "      self.listed_in_ranks = self.listed_in_ranks + ['Rare']\n",
        "      # # Creating dictionary for mapping categories \n",
        "      for index in range(0,len(self.listed_in_ranks)):\n",
        "        self.listed_in_dict[self.listed_in_ranks[index]] = index\n",
        "\n",
        "      # # replacing categories\n",
        "      X[self.variables] = X[self.variables].map(self.listed_in_dict) \n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "rtfh2ccWDNNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class handleMixLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "    self.variables = variables\n",
        "    self.keys:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.tol = tol\n",
        "    self.target = target\n",
        "    self.all_unique_feature_type:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.top_unique_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.unique_rare_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "\n",
        "\n",
        "\n",
        "  # we check the top 10 cardinal value which have monotonic relation with target column store that in keys\n",
        "  # go through the column if it have mixed or comma seperated values the carefully store all unique cardinal values store in all_unique_feature_type\n",
        "  # based on tolerance it take top cardinal values default value is 10 and store those top values in top_unique_feature_type_\n",
        "  def fit(self, X: pd.DataFrame,y:pd.Series):\n",
        "          X = X.dropna().copy()\n",
        "          X[self.target] = y\n",
        "          X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "        \n",
        "          if isinstance(self.variables,list):\n",
        "            self.all_unique_feature_type = list()\n",
        "            self.top_unique_feature_type_ = list()\n",
        "            self.unique_rare_feature_type_ = list()\n",
        "\n",
        "            for index, variable in enumerate(self.variables): \n",
        "              # fetch all top categories of variable related to target variables in descending order \n",
        "              self.top_unique_feature_type_.append({variable:list(np.unique(sum(pd.Series([key for key in X.groupby(variable)[self.target].mean().sort_values(ascending=False).keys()][:self.tol[index]]).str.split(r'(?:,|;)\\s*').dropna().to_numpy(), []))) + ['Rare']})\n",
        "\n",
        "              # remove duplicated categories as they are all mixed up\n",
        "              self.all_unique_feature_type.append({variable:list(np.unique(sum(X[variable].str.split(r'(?:,|;)\\s*').dropna().to_numpy(), [])))}) \n",
        "              \n",
        "              # Seperate less related unique categories from top categorials for rare labeling\n",
        "              self.unique_rare_feature_type_.append({variable:[item for item in self.all_unique_feature_type[index][variable] if item not in self.top_unique_feature_type_[index][variable]]})\n",
        "            \n",
        "              \n",
        "          if isinstance(self.variables,str):\n",
        "            self.all_unique_feature_type = list()\n",
        "            self.top_unique_feature_type_ = list()\n",
        "            self.unique_rare_feature_type_ = list()  \n",
        "\n",
        "            # fetch all top categories of variable related to target variables in descending order \n",
        "            self.top_unique_feature_type_ = list(np.unique(sum(pd.Series([key for key in X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).keys()][:self.tol]).str.split(r'(?:,|;)\\s*').dropna().to_numpy(), [])))  + ['Rare']       \n",
        "\n",
        "            # remove duplicated categories as they are all mixed up\n",
        "            self.all_unique_feature_type.append({self.variables:list(np.unique(sum(X[self.variables].str.split(r'(?:,|;)\\s*').dropna().to_numpy(), [])))}) \n",
        "              \n",
        "            # Seperate less related unique categories from top categorials for rare labeling\n",
        "            self.unique_rare_feature_type_.append({self.variables:[item for item in self.all_unique_feature_type if item not in self.top_unique_feature_type_]})\n",
        "\n",
        "          return self\n",
        "\n",
        "\n",
        "\n",
        "  def transform(self, X: pd.DataFrame):\n",
        "        X = X.copy()\n",
        "        \n",
        "        if isinstance(self.variables,list):\n",
        "          for index, variable in enumerate(self.variables):\n",
        "            # adding new columns of unique labels in datasets\n",
        "            for value in self.top_unique_feature_type_[index][variable]:\n",
        "                 X[f'{variable}_{value}'] = np.where(X[variable].isin([value]),1,0)\n",
        "\n",
        "            print(np.unique(np.where(X[variable].isin(self.unique_rare_feature_type_[index][variable]),1,0), return_counts=True))\n",
        "            print(np.unique( np.where(X[variable].str.findall('|'.join(self.unique_rare_feature_type_[index][variable])).str.len()>0,1,0),return_counts=True))\n",
        " \n",
        "            X[f'{variable}_Rare'] = np.where(X[variable].str.findall('|'.join(self.unique_rare_feature_type_[index][variable])).str.len()>0,1,0)    \n",
        "\n",
        "        if isinstance(self.variables,str):  \n",
        "            for value in self.top_unique_feature_type_:\n",
        "                 X[f'{self.variables}_{value}'] = np.where(X[self.variables].isin([value]),1,0)\n",
        "\n",
        "            print(np.unique(np.where(X[self.variables].isin(self.unique_rare_feature_type_),1,0), return_counts=True))\n",
        "            print(np.unique( np.where(X[self.variables].str.findall('|'.join(self.unique_rare_feature_type_)).str.len()>0,1,0),return_counts=True))\n",
        " \n",
        "            X[f'{self.variables}_Rare'] = np.where(X[self.variables].str.findall('|'.join(self.unique_rare_feature_type_)).str.len()>0,1,0)\n",
        "       \n",
        "        X = X.drop(self.variables,axis=1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "kuT2LRbrCq31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class featureSelection(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,alpha,random_state):\n",
        "    self.selected_feats = None\n",
        "    self.__alpha = alpha\n",
        "    self.__random_state = random_state \n",
        "    self.sel_ = None\n",
        "\n",
        "  def fit(self,X,y):\n",
        "   self.sel_ = SelectFromModel(Lasso(alpha=self.__alpha, random_state=self.__random_state))\n",
        "   self.sel_.fit(X, y)  \n",
        "   return self\n",
        "\n",
        "  def transform(self,X): \n",
        "   self.selected_feats = X.columns[(self.sel_.get_support())]\n",
        "   return X[self.selected_feats]"
      ],
      "metadata": {
        "id": "LJB68POtdJnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZomatoModelTrain(handleMixLabels,handleRankingLabels,featureSelection):\n",
        "\n",
        "  def __init__(self,df):\n",
        "    self.__df = df\n",
        "    self.__target = 'approx_cost(for two people)'\n",
        "    self.__df[self.__target] = self.__df[self.__target].str.replace(',','').astype(float)\n",
        "    self.__random_state = 100\n",
        "    self.__alpha = 0.001\n",
        "    self.__test_size = 0.33\n",
        "    self.__handleRankingLabels = handleRankingLabels\n",
        "    self.__handleMixLabels = handleMixLabels\n",
        "    self.__featureSelection = featureSelection\n",
        "    self.__variable_to_drop = ['url','address','phone','reviews_list','name','dish_liked','menu_item'] + [self.__target]\n",
        "    self.__AddMissingIndicatorVariables = ['votes','rate']\n",
        "    self.__MeanMedianImputerVarables = ['votes']\n",
        "    self.__CategoricalImputerModeVarables = ['rate','cuisines','rest_type']\n",
        "    self.__LogTransformerVarables = ['votes']\n",
        "    self.__OrdinalEncoderVariables = ['rate']\n",
        "    self.__OneHotEncoderVariables = ['online_order','book_table']\n",
        "    self.__handleRankingLabels_var = {'variables':['listed_in(type)','listed_in(city)','location'],'tolerance':[10,15,15]}\n",
        "    self.__handleMixLabels_var ={'variables':['rest_type','cuisines'],'tolerance':[10,15]}\n",
        "\n",
        "\n",
        "  def applyModelTrain(self):\n",
        "    X_train,X_test,y_train,y_test = self.__dataSpliter()\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)  \n",
        "    return X_train,X_test,y_train.fillna(y_train.median()),y_test.fillna(y_test.median())\n",
        "\n",
        "  # Splits the data into train and test set\n",
        "  def __dataSpliter(self):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df.drop(self.__variable_to_drop,axis=1), df[self.__target], test_size=self.__test_size, random_state=42)\n",
        "    X_train,X_test,y_train,y_test = X_train.reset_index().drop('index',axis=1),X_test.reset_index().drop('index',axis=1),y_train.reset_index().drop('index',axis=1),y_test.reset_index().drop('index',axis=1)\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  # This method andle noisy data from rate and votes columns\n",
        "  def __dataCleanar(self,X_train,X_test):\n",
        "    # replacing '-' with nan in rate variable\n",
        "    X_train['rate'] = X_train['rate'].replace('-',np.nan)  \n",
        "    X_test['rate'] = X_test['rate'].replace('-',np.nan)\n",
        "\n",
        "    # replacing '0' with nan in votes variable\n",
        "    X_train['votes'] = X_train['votes'].replace(0,np.nan)\n",
        "    X_test['votes'] = X_test['votes'].replace(0,np.nan)\n",
        "    \n",
        "    # replacing '/5' with ' in rates variable\n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    \n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "\n",
        "    return X_train,X_test\n",
        "\n",
        "  # This method is for rate column where based on certain ranges we made this column to categorical oridinal variable\n",
        "  def handleRating(self,X_train,X_test,feature):\n",
        "    return np.where(X_train[feature]==np.nan,np.nan,np.where(X_train[feature]==0,'New',np.where(X_train[feature]<2.5,'Poor',np.where((X_train[feature]>2.5) | (X_train[feature]<3.5),'Average','Good')))),np.where(X_test[feature]==np.nan,np.nan,np.where(X_test[feature]==0,'New',np.where(X_test[feature]<2.5,'Poor',np.where((X_test[feature]>2.5) | (X_test[feature]<3.5),'Average','Good')))) \n",
        "\n",
        "  def featurePipeline(self):\n",
        "    pipe = Pipeline([\n",
        "      #  Missing indicator\n",
        "      ('Add missing indicator',AddMissingIndicator(\n",
        "          variables=self.__AddMissingIndicatorVariables)),\n",
        "    \n",
        "      #   Median Missing Imputation\n",
        "      ('Median Missing Imputation',MeanMedianImputer(\n",
        "          imputation_method='median', variables=self.__MeanMedianImputerVarables)),\n",
        "\n",
        "      #   Mode Missing Imputation\n",
        "      ('Mode Missing Imputation',CategoricalImputer(\n",
        "          imputation_method='frequent', variables=self.__CategoricalImputerModeVarables)),        \n",
        "\n",
        "      # Feature Transformation\n",
        "      ('LogTransformer',LogTransformer(\n",
        "          variables=self.__LogTransformerVarables)),\n",
        "\n",
        "      #  Ordinal Encoder\n",
        "      ('OrdinalEncoder',OrdinalEncoder(\n",
        "          encoding_method='ordered',variables=self.__OrdinalEncoderVariables)),\n",
        "\n",
        "      #  OneHotEncoder\n",
        "      ('OneHotEncoder',OneHotEncoder(\n",
        "          drop_last=True,variables=self.__OneHotEncoderVariables)),\n",
        "\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels listed_in(type)',self.__handleRankingLabels(\n",
        "          variables=self.__handleRankingLabels_var['variables'],tol=self.__handleRankingLabels_var['tolerance'],target=self.__target)),        \n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation cuisines', self.__handleMixLabels(\n",
        "          variables=self.__handleMixLabels_var['variables'],tol=self.__handleMixLabels_var['tolerance'],target=self.__target)), \n",
        "\n",
        "      # #  feature selection\n",
        "      # ('feature selection',featureSelection(alpha=self.__alpha, random_state=self.__random_state)),\n",
        "\n",
        "      # Model\n",
        "      # ('Random Forest Model',RandomForestRegressor(bootstrap= True,max_depth= 10,min_samples_leaf= 2,min_samples_split= 2,n_estimators= 100,oob_score= True))\n",
        "    ])\n",
        "\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "kwAtkCxRckCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/zomato.csv')"
      ],
      "metadata": {
        "id": "3i3mVysuCc3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zmt = ZomatoModelTrain(df)"
      ],
      "metadata": {
        "id": "DYh2D1IeCdeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = zmt.applyModelTrain()"
      ],
      "metadata": {
        "id": "WMsJ-sMoCj2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.dropna().reset_index().drop('index',axis=1)\n",
        "y_train = y_train.dropna().reset_index().drop('index',axis=1)[:X_train.shape[0]]"
      ],
      "metadata": {
        "id": "ARs41vaWsC20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el2GirrTtFtp",
        "outputId": "08cfa223-012a-4fc3-ea5a-10402a919194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27812, 9), (27812, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NfVCanPHT4R",
        "outputId": "2ce908ea-0113-41b4-c9db-2b533d37376f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27812 entries, 0 to 27811\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   online_order     27812 non-null  object \n",
            " 1   book_table       27812 non-null  object \n",
            " 2   rate             27812 non-null  float64\n",
            " 3   votes            27812 non-null  float64\n",
            " 4   location         27812 non-null  object \n",
            " 5   rest_type        27812 non-null  object \n",
            " 6   cuisines         27812 non-null  object \n",
            " 7   listed_in(type)  27812 non-null  object \n",
            " 8   listed_in(city)  27812 non-null  object \n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'],X_test['rate'] = zmt.handleRating(X_train,X_test,'rate')"
      ],
      "metadata": {
        "id": "7SOrtuTNybyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'].unique(),X_test['rate'].unique()"
      ],
      "metadata": {
        "id": "OrXPlcuFyzJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f0ae12-d339-4e87-db08-af2591141ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Average', 'Poor'], dtype=object),\n",
              " array(['Average', 'New', 'Good', 'Poor'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = zmt.featurePipeline()"
      ],
      "metadata": {
        "id": "kk7jZixleuFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "QDKT_cENEUZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# record start time\n",
        "start = time.time()\n",
        "\n",
        "train = pipe.transform(X_train)\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        " \n",
        "# print the difference between start\n",
        "# and end time in milli. secs\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start) * 10**3, \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktM_stvwEGgk",
        "outputId": "2a32ee4a-df32-42fd-95a0-0606cdf0cd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([25370,  2442]))\n",
            "(array([0, 1]), array([23106,  4706]))\n",
            "(array([0, 1]), array([26706,  1106]))\n",
            "(array([0, 1]), array([15701, 12111]))\n",
            "The time of execution of above program is : 472.80359268188477 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "8FAL7dvsArGK",
        "outputId": "3ffa0fc3-afb1-46f9-9ff1-d10ca4abc0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       rate     votes  location  listed_in(type)  listed_in(city)  \\\n",
              "15464     1  2.890372        16                3               14   \n",
              "22469     1  6.862758        16                5                7   \n",
              "17710     1  4.248495        16                5               16   \n",
              "16709     1  4.442651        16                5               16   \n",
              "7652      1  5.135798        16                3               16   \n",
              "\n",
              "       online_order_Yes  book_table_No  rest_type_Bakery  \\\n",
              "15464                 1              1                 0   \n",
              "22469                 1              0                 0   \n",
              "17710                 1              1                 0   \n",
              "16709                 1              1                 0   \n",
              "7652                  0              1                 0   \n",
              "\n",
              "       rest_type_Beverage Shop  rest_type_Cafe  rest_type_Casual Dining  \\\n",
              "15464                        0               0                        0   \n",
              "22469                        0               0                        1   \n",
              "17710                        0               0                        0   \n",
              "16709                        0               0                        0   \n",
              "7652                         0               0                        0   \n",
              "\n",
              "       rest_type_Dessert Parlor  rest_type_Fine Dining  rest_type_Food Court  \\\n",
              "15464                         0                      0                     0   \n",
              "22469                         0                      0                     0   \n",
              "17710                         1                      0                     0   \n",
              "16709                         0                      0                     0   \n",
              "7652                          0                      0                     0   \n",
              "\n",
              "       rest_type_Meat Shop  rest_type_Microbrewery  rest_type_Pub  \\\n",
              "15464                    0                       0              0   \n",
              "22469                    0                       0              0   \n",
              "17710                    0                       0              0   \n",
              "16709                    0                       0              0   \n",
              "7652                     0                       0              0   \n",
              "\n",
              "       rest_type_Quick Bites  rest_type_Rare  cuisines_Arabian  cuisines_BBQ  \\\n",
              "15464                      1               0                 0             0   \n",
              "22469                      0               0                 0             0   \n",
              "17710                      0               0                 0             0   \n",
              "16709                      0               0                 0             0   \n",
              "7652                       1               0                 0             0   \n",
              "\n",
              "       cuisines_Bakery  cuisines_Beverages  cuisines_Biryani  cuisines_Cafe  \\\n",
              "15464                0                   0                 0              0   \n",
              "22469                0                   0                 0              0   \n",
              "17710                0                   0                 0              0   \n",
              "16709                0                   0                 0              0   \n",
              "7652                 0                   0                 0              0   \n",
              "\n",
              "       cuisines_Chettinad  cuisines_Chinese  cuisines_Continental  \\\n",
              "15464                   0                 0                     0   \n",
              "22469                   0                 0                     0   \n",
              "17710                   0                 0                     0   \n",
              "16709                   0                 0                     0   \n",
              "7652                    0                 0                     0   \n",
              "\n",
              "       cuisines_Desserts  cuisines_Fast Food  cuisines_French  \\\n",
              "15464                  0                   0                0   \n",
              "22469                  0                   0                0   \n",
              "17710                  0                   0                0   \n",
              "16709                  0                   0                0   \n",
              "7652                   0                   0                0   \n",
              "\n",
              "       cuisines_German  cuisines_Ice Cream  cuisines_Italian  cuisines_Juices  \\\n",
              "15464                0                   0                 0                0   \n",
              "22469                0                   0                 0                0   \n",
              "17710                0                   0                 0                0   \n",
              "16709                0                   0                 0                0   \n",
              "7652                 0                   0                 0                0   \n",
              "\n",
              "       cuisines_Middle Eastern  cuisines_Momos  cuisines_North Indian  \\\n",
              "15464                        0               0                      0   \n",
              "22469                        0               0                      0   \n",
              "17710                        0               0                      0   \n",
              "16709                        0               0                      0   \n",
              "7652                         0               0                      0   \n",
              "\n",
              "       cuisines_Oriya  cuisines_Rolls  cuisines_Seafood  \\\n",
              "15464               0               0                 0   \n",
              "22469               0               0                 0   \n",
              "17710               0               0                 0   \n",
              "16709               0               0                 0   \n",
              "7652                0               0                 0   \n",
              "\n",
              "       cuisines_South Indian  cuisines_Spanish  cuisines_Steak  cuisines_Thai  \\\n",
              "15464                      0                 0               0              0   \n",
              "22469                      0                 0               0              0   \n",
              "17710                      0                 0               0              0   \n",
              "16709                      0                 0               0              0   \n",
              "7652                       0                 0               0              0   \n",
              "\n",
              "       cuisines_Turkish  cuisines_Rare  \n",
              "15464                 0              0  \n",
              "22469                 0              1  \n",
              "17710                 0              0  \n",
              "16709                 0              0  \n",
              "7652                  0              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89e5852e-59c6-4d21-be6a-64923af5d983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>votes</th>\n",
              "      <th>location</th>\n",
              "      <th>listed_in(type)</th>\n",
              "      <th>listed_in(city)</th>\n",
              "      <th>online_order_Yes</th>\n",
              "      <th>book_table_No</th>\n",
              "      <th>rest_type_Bakery</th>\n",
              "      <th>rest_type_Beverage Shop</th>\n",
              "      <th>rest_type_Cafe</th>\n",
              "      <th>rest_type_Casual Dining</th>\n",
              "      <th>rest_type_Dessert Parlor</th>\n",
              "      <th>rest_type_Fine Dining</th>\n",
              "      <th>rest_type_Food Court</th>\n",
              "      <th>rest_type_Meat Shop</th>\n",
              "      <th>rest_type_Microbrewery</th>\n",
              "      <th>rest_type_Pub</th>\n",
              "      <th>rest_type_Quick Bites</th>\n",
              "      <th>rest_type_Rare</th>\n",
              "      <th>cuisines_Arabian</th>\n",
              "      <th>cuisines_BBQ</th>\n",
              "      <th>cuisines_Bakery</th>\n",
              "      <th>cuisines_Beverages</th>\n",
              "      <th>cuisines_Biryani</th>\n",
              "      <th>cuisines_Cafe</th>\n",
              "      <th>cuisines_Chettinad</th>\n",
              "      <th>cuisines_Chinese</th>\n",
              "      <th>cuisines_Continental</th>\n",
              "      <th>cuisines_Desserts</th>\n",
              "      <th>cuisines_Fast Food</th>\n",
              "      <th>cuisines_French</th>\n",
              "      <th>cuisines_German</th>\n",
              "      <th>cuisines_Ice Cream</th>\n",
              "      <th>cuisines_Italian</th>\n",
              "      <th>cuisines_Juices</th>\n",
              "      <th>cuisines_Middle Eastern</th>\n",
              "      <th>cuisines_Momos</th>\n",
              "      <th>cuisines_North Indian</th>\n",
              "      <th>cuisines_Oriya</th>\n",
              "      <th>cuisines_Rolls</th>\n",
              "      <th>cuisines_Seafood</th>\n",
              "      <th>cuisines_South Indian</th>\n",
              "      <th>cuisines_Spanish</th>\n",
              "      <th>cuisines_Steak</th>\n",
              "      <th>cuisines_Thai</th>\n",
              "      <th>cuisines_Turkish</th>\n",
              "      <th>cuisines_Rare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15464</th>\n",
              "      <td>1</td>\n",
              "      <td>2.890372</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22469</th>\n",
              "      <td>1</td>\n",
              "      <td>6.862758</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17710</th>\n",
              "      <td>1</td>\n",
              "      <td>4.248495</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16709</th>\n",
              "      <td>1</td>\n",
              "      <td>4.442651</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7652</th>\n",
              "      <td>1</td>\n",
              "      <td>5.135798</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89e5852e-59c6-4d21-be6a-64923af5d983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89e5852e-59c6-4d21-be6a-64923af5d983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89e5852e-59c6-4d21-be6a-64923af5d983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['rest_type_Bakery'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-vWmuI1iLlY",
        "outputId": "29d22428-54a0-4fb3-9e74-b84db0c5a0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    27341\n",
              "1      471\n",
              "Name: rest_type_Bakery, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['rest_type_Rare'].value_counts()"
      ],
      "metadata": {
        "id": "L3qSYU1QigLH",
        "outputId": "7622597b-b423-46a7-9e2c-5d561a6894c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23106\n",
              "1     4706\n",
              "Name: rest_type_Rare, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['cuisines_Rare'].value_counts()"
      ],
      "metadata": {
        "id": "aVdfhCWNihmq",
        "outputId": "98fb495d-8ea2-4b4a-c72d-4e375df489fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    15701\n",
              "1    12111\n",
              "Name: cuisines_Rare, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fs = featureSelection(alpha=0.01,random_state=100)"
      ],
      "metadata": {
        "id": "ABsFKMEoDWI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = fs.fit(train,y_train)"
      ],
      "metadata": {
        "id": "Uirfx3HhR2HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = fs.transform(train)"
      ],
      "metadata": {
        "id": "um6pT90ADmZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(bootstrap= True,max_depth= 10,min_samples_leaf= 2,min_samples_split= 2,n_estimators= 100,oob_score= True)"
      ],
      "metadata": {
        "id": "1W051IqONBRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = rf.fit(train,y_train)"
      ],
      "metadata": {
        "id": "GfHO8w5NdjqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = rf.predict(train)"
      ],
      "metadata": {
        "id": "yk2QQEGpdkqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error"
      ],
      "metadata": {
        "id": "AIR7ZQcSdmI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32DZQTXjdnX8",
        "outputId": "cdc51cb5-9f32-407a-d9e7-938a2c1f9c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06697711978959486"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_train,pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we1lG5QAdocj",
        "outputId": "e36792e3-9f37-429d-eb7c-20304020f1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "425.49313257413894"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_train,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7nt8zzFdphC",
        "outputId": "e5267c99-c267-4390-da77-dd3601c726f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291.17468702030015"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "residual_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "QC2PDF-hdqrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# record start time\n",
        "start = time.time()\n",
        "\n",
        "test = pipe.transform(X_test)\n",
        "\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        " \n",
        "# print the difference between start\n",
        "# and end time in milli. secs\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start) * 10**3, \"ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC0ZmRqLds5l",
        "outputId": "12f3cae4-0a69-4e7f-9ecb-abe16d8810c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0, 1]), array([15432,  1635]))\n",
            "(array([0, 1]), array([14038,  3029]))\n",
            "(array([0, 1]), array([16443,   624]))\n",
            "(array([0, 1]), array([10229,  6838]))\n",
            "The time of execution of above program is : 520.2810764312744 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = fs.transform(test)"
      ],
      "metadata": {
        "id": "-c2wKFAndt9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY7aoZxVfjHx",
        "outputId": "78b011b5-a872-4343-c19d-8e42c95feeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rate                        3330\n",
              "votes                          0\n",
              "location                       0\n",
              "listed_in(type)                0\n",
              "listed_in(city)                0\n",
              "online_order_Yes               0\n",
              "book_table_No                  0\n",
              "rest_type_Bakery               0\n",
              "rest_type_Beverage Shop        0\n",
              "rest_type_Cafe                 0\n",
              "rest_type_Casual Dining        0\n",
              "rest_type_Dessert Parlor       0\n",
              "rest_type_Fine Dining          0\n",
              "rest_type_Food Court           0\n",
              "rest_type_Microbrewery         0\n",
              "rest_type_Pub                  0\n",
              "rest_type_Quick Bites          0\n",
              "rest_type_Rare                 0\n",
              "cuisines_Arabian               0\n",
              "cuisines_BBQ                   0\n",
              "cuisines_Beverages             0\n",
              "cuisines_Biryani               0\n",
              "cuisines_Cafe                  0\n",
              "cuisines_Chettinad             0\n",
              "cuisines_Chinese               0\n",
              "cuisines_Continental           0\n",
              "cuisines_Desserts              0\n",
              "cuisines_Fast Food             0\n",
              "cuisines_Ice Cream             0\n",
              "cuisines_Italian               0\n",
              "cuisines_North Indian          0\n",
              "cuisines_Oriya                 0\n",
              "cuisines_Rolls                 0\n",
              "cuisines_Seafood               0\n",
              "cuisines_South Indian          0\n",
              "cuisines_Spanish               0\n",
              "cuisines_Thai                  0\n",
              "cuisines_Turkish               0\n",
              "cuisines_Rare                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6Gbr_aNfeHJ",
        "outputId": "e57cc25c-f2d0-4c32-ce05-51bf4dad8e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17067 entries, 0 to 17066\n",
            "Data columns (total 39 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   rate                      13737 non-null  float64\n",
            " 1   votes                     17067 non-null  float64\n",
            " 2   location                  17067 non-null  int64  \n",
            " 3   listed_in(type)           17067 non-null  int64  \n",
            " 4   listed_in(city)           17067 non-null  int64  \n",
            " 5   online_order_Yes          17067 non-null  int64  \n",
            " 6   book_table_No             17067 non-null  int64  \n",
            " 7   rest_type_Bakery          17067 non-null  int64  \n",
            " 8   rest_type_Beverage Shop   17067 non-null  int64  \n",
            " 9   rest_type_Cafe            17067 non-null  int64  \n",
            " 10  rest_type_Casual Dining   17067 non-null  int64  \n",
            " 11  rest_type_Dessert Parlor  17067 non-null  int64  \n",
            " 12  rest_type_Fine Dining     17067 non-null  int64  \n",
            " 13  rest_type_Food Court      17067 non-null  int64  \n",
            " 14  rest_type_Microbrewery    17067 non-null  int64  \n",
            " 15  rest_type_Pub             17067 non-null  int64  \n",
            " 16  rest_type_Quick Bites     17067 non-null  int64  \n",
            " 17  rest_type_Rare            17067 non-null  int64  \n",
            " 18  cuisines_Arabian          17067 non-null  int64  \n",
            " 19  cuisines_BBQ              17067 non-null  int64  \n",
            " 20  cuisines_Beverages        17067 non-null  int64  \n",
            " 21  cuisines_Biryani          17067 non-null  int64  \n",
            " 22  cuisines_Cafe             17067 non-null  int64  \n",
            " 23  cuisines_Chettinad        17067 non-null  int64  \n",
            " 24  cuisines_Chinese          17067 non-null  int64  \n",
            " 25  cuisines_Continental      17067 non-null  int64  \n",
            " 26  cuisines_Desserts         17067 non-null  int64  \n",
            " 27  cuisines_Fast Food        17067 non-null  int64  \n",
            " 28  cuisines_Ice Cream        17067 non-null  int64  \n",
            " 29  cuisines_Italian          17067 non-null  int64  \n",
            " 30  cuisines_North Indian     17067 non-null  int64  \n",
            " 31  cuisines_Oriya            17067 non-null  int64  \n",
            " 32  cuisines_Rolls            17067 non-null  int64  \n",
            " 33  cuisines_Seafood          17067 non-null  int64  \n",
            " 34  cuisines_South Indian     17067 non-null  int64  \n",
            " 35  cuisines_Spanish          17067 non-null  int64  \n",
            " 36  cuisines_Thai             17067 non-null  int64  \n",
            " 37  cuisines_Turkish          17067 non-null  int64  \n",
            " 38  cuisines_Rare             17067 non-null  int64  \n",
            "dtypes: float64(2), int64(37)\n",
            "memory usage: 5.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = rf.predict(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "A33uI4KbdwRi",
        "outputId": "a801687b-f9bc-4750-a66c-aabe363ec23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f4ba30adec66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test,pred_test)"
      ],
      "metadata": {
        "id": "CyrUp-XzdxZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(mean_squared_error(y_test,pred_test))"
      ],
      "metadata": {
        "id": "lN2DA3iadyeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_test,pred_test)"
      ],
      "metadata": {
        "id": "kyt-Cjskd1sb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}